# -*- coding: utf-8 -*-
"""content-collab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k8aZTA8n5vnIFkvOyrKm1zz6izfax66h

# **CONTENT-BASED COLLABORATIVE RECOMMENDER SYSTEM**

Import library yang di butuhkan
"""

import pandas as pd
import numpy as np 
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
import seaborn as sns
import re

"""# **Data loading**"""

! pip install kaggle

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  
# Then move kaggle.json into the folder where the API expects to find it.
!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d CooperUnion/anime-recommendations-database

! unzip /content/anime-recommendations-database.zip

"""Import dataset"""

anime_df = pd.read_csv('anime.csv')
rating_df = pd.read_csv('rating.csv')

"""# **Data Understanding**
**Variabel-variabel pada dataset adalah sebagai berikut:**
**anime.csv**
- anime_id : id unik anime
- name : nama anime
- genre : genre anime
- type : tipe siaran anime (TV, Movie, etc)
- episodes : jumlah episode anime
- rating : rating anime
- members : total user

**rating.csv**
- user_id : id unik user
- anime_id : id unik anime
- rating : rating yang diberikan oleh user

"""

anime_df.head(10)

"""# **Memeriksa informasi pada table anime**"""

anime_df.info()

"""informasi dataframe anime.csv

# **Menghilangkan missing value**
"""

anime_df.isnull().sum()

anime_df =  anime_df.dropna()
anime_df.isnull().sum()

"""Jika dilihat dari data anime di atas. Terdapat sejumlah kolom missing value pada data anime.csv.

**Membersihkan simbol-simbol**
"""

def text_cleaning(text):
    text = re.sub(r'&quot;', '', text)
    text = re.sub(r'.hack//', '', text)
    text = re.sub(r'&#039;', '', text)
    text = re.sub(r'A&#039;s', '', text)
    text = re.sub(r'I&#039;', 'I\'', text)
    text = re.sub(r'&amp;', 'and', text)
    
    return text

anime_df['name'] = anime_df['name'].apply(text_cleaning)

"""Membersihkan karakter yang tidak bisa di baca, kemungkinan adanya huruf jepang"""

anime_df['genre'] = pd.DataFrame(anime_df['genre'].str.replace('|', ',', regex=True))

"""# **Visualization**"""

genre_data = (anime_df.set_index(anime_df.columns.drop('genre',1).tolist())['genre']
               .str.split(',', expand=True)
               .stack()
               .reset_index()
               .rename(columns={0:'genre'})
               .loc[:, anime_df.columns]
               )

type_count = anime_df['type'].value_counts()

sns.barplot(x=type_count.values,
            y=type_count.index,
            palette='muted').set_title('Anime Types')

plt.tight_layout()
plt.show()

"""Anime bertipe TV mampunyai jumlah paling banyak

# **Memeriksa informasi dari data table rating**
"""

rating_df.info()

"""Informasi Dataframe rating.csv

"""

rating_df = rating_df.drop(range(2000, 7813737))
rating_df

"""**Menghilangkan nilai -1 pada kolom rating**"""

rating_df["rating"].replace({-1: np.nan}, inplace=True)
rating_df.head()

"""**Menghapus kolom pertama pada table rating**"""

rating_df = rating_df.dropna(axis = 0, how ='any')
rating_df

rating_count = rating_df['rating'].value_counts().sort_index()

sns.barplot(x=rating_count.index,
            y=rating_count.values,
            palette='magma').set_title('Comparison of the number of ratings from 1 to 10');

"""Rating 7 paling banyak diberikan pada dataset ini

### **Content Based**

**Data Preparation**
"""

tf = TfidfVectorizer()
tf.fit(anime_df['genre']) 
tf.get_feature_names_out()

"""Tfid Vectorizer"""

tfidf_matrix = tf.fit_transform(anime_df['genre']) 

tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names_out(),
    index=anime_df.name
).sample(22, axis=1).sample(10, axis=0)

"""**Cosine Similarity**

mencari kemiripan antar item

# **Transformasi data kedalam bentuk matriks**
"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=anime_df['name'], columns=anime_df['name'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""**Membuat fungsi rekomendasi** """

def anime_recommendation(nama_anime, similarity_data=cosine_sim_df, items=anime_df[['name', 'genre']], k=5):
    
    index = similarity_data.loc[:,nama_anime].to_numpy().argpartition(
        range(-1, -k, -1))
    
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    closest = closest.drop(nama_anime, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

"""Test rekomendasi"""

anime_df[anime_df.name.eq('One Piece')]

anime_recommendation('One Piece')

anime_recommendation('AD Police')

"""### **COLLABORATIVE**"""

rating_df

"""memanggil dataset rating.csv

**Data encoding**
"""

user_ids = rating_df['user_id'].unique().tolist()
print('list user_id: ', user_ids)

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded value to user_id: ', user_encoded_to_user)

"""**Memisahkan user_id dan anime_id**"""

anime_ids = rating_df['anime_id'].unique().tolist()

anime_to_anime_encoded = {x: i for i, x in enumerate(anime_ids)}

anime_encoded_to_anime = {i: x for i, x in enumerate(anime_ids)}

rating_df['user'] = rating_df['user_id'].map(user_to_user_encoded)

rating_df['anime'] = rating_df['anime_id'].map(anime_to_anime_encoded)

num_users = len(user_to_user_encoded)
print(num_users)

num_anime = len(anime_encoded_to_anime)
print(num_anime)

min_rating = min(rating_df['rating'])

max_rating = max(rating_df['rating'])
 
print('Number of User: {}, Number of Anime: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_anime, min_rating, max_rating
))

rating_df = rating_df.sample(frac=1, random_state=42)
rating_df

"""mengacak urutan data

**Train n Split**
"""

x = rating_df[['user', 'anime']].values

y = rating_df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * rating_df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""Membuat Fungsi rekomendasi"""

class RecommenderNet(tf.keras.Model):

  def __init__(self, num_users, num_anime, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_anime = num_anime
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.anime_embedding = layers.Embedding(
        num_anime,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.anime_bias = layers.Embedding(num_anime, 1)
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    anime_vector = self.anime_embedding(inputs[:, 1])
    anime_bias = self.anime_bias(inputs[:, 1])
 
    dot_user_anime = tf.tensordot(user_vector, anime_vector, 2) 
 
    x = dot_user_anime + user_bias + anime_bias
    
    return tf.nn.sigmoid(x)
    
model = RecommenderNet(num_users, num_anime, 50)
 
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""**Train model**"""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 20,
    validation_data = (x_val, y_val)
)

"""Visualisasi train dan test"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Membuat fungsi rekomendasi"""

anime_df = anime_df
ratingh_df = rating_df

userID = rating_df.user_id.sample(1).iloc[0]
anime_watched_by_user = rating_df[rating_df.user_id == userID]
 
anime_not_watched = anime_df[~anime_df['anime_id'].isin(anime_watched_by_user.anime_id.values)]['anime_id'] 
anime_not_watched = list(
    set(anime_not_watched)
    .intersection(set(anime_to_anime_encoded.keys()))
)
 
anime_not_watched = [[anime_to_anime_encoded.get(x)] for x in anime_not_watched]
user_encoder = user_to_user_encoded.get(userID)
user_anime_array = np.hstack(
    ([[user_encoder]] * len(anime_not_watched), anime_not_watched)
)

"""Menggabungkan hasil dari content based dan collaborative"""

ratings = model.predict(user_anime_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_anime_ids = [
    anime_encoded_to_anime.get(anime_not_watched[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(userID))
print('===' * 9)
print('Anime with high ratings from user')
print('----' * 8)
 
top_anime_user = (
    anime_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .anime_id.values
)
 
anime_df_rows = anime_df[anime_df['anime_id'].isin(top_anime_user)]
for row in anime_df_rows.itertuples():
    print(row.name, ':', row.genre)
 
print('----' * 8)
print('Top 10 anime recommendation')
print('----' * 8)
 
recommended_anime = anime_df[anime_df['anime_id'].isin(recommended_anime_ids)]
for row in recommended_anime.itertuples():
    print(row.name, ':', row.genre)